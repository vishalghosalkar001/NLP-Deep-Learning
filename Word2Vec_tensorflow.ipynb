{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec-tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Word2Vec with Tensorflow\n",
        "\n",
        "There are many techniques to get word embeddings, we will discuss one technique which has gained a lot of fame, the one and only, word2vec. Contrary to popular belief, word2vec is not a deep network, it only has 3 layers!\n",
        "Note : word2vec has a lot of technical details which I will skip over to make the understanding a lot easier."
      ],
      "metadata": {
        "id": "0Ex9vGDvUjga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How word2vec works:\n",
        "The idea behind word2vec is that:\n",
        "1. Take a 3 layer neural network. (1 input layer + 1 hidden layer + 1 output layer)\n",
        "1. Feed it a word and train it to predict its neighbouring word.\n",
        "1. Remove the last (output layer) and keep the input and hidden layer.\n",
        "1. Now, input a word from within the vocabulary. The output given at the hidden layer is the ‘word embedding’ of the input word."
      ],
      "metadata": {
        "id": "SzYxLiuPVDQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "oTTR-Pxt73hM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ex3JKo_KUjLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da98ca0-159b-467f-96f0-f4209e08d360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_raw = 'He is the king . The king is royal . She is the royal  queen .'\n",
        "# convert to lower case\n",
        "corpus_raw = corpus_raw.lower()"
      ],
      "metadata": {
        "id": "Dy8YSFyU7-Pj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dictionary which translates words to integers and integers to words. This will come in handy later."
      ],
      "metadata": {
        "id": "gEGynlYGVZou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for word in corpus_raw.split():\n",
        "    if word != '.': # because we don't want to treat . as a word\n",
        "        words.append(word)\n",
        "words = set(words) # so that all duplicate words are removed\n",
        "word2int = {}\n",
        "int2word = {}\n",
        "vocab_size = len(words) # gives the total number of unique words\n",
        "print('vocab size = ', vocab_size)\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "    int2word[i] = word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB_f-heXVTCv",
        "outputId": "16c7e6eb-0ef2-4390-be16-d94d32eedc0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size =  7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2int['queen'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwa-fQpzVvez",
        "outputId": "c1e4ec0a-d1a6-44f0-ab16-3a357606a867"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(int2word[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV4yyOHEVyYh",
        "outputId": "d768bb47-e404-49aa-f915-b0ba65286455"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# raw sentences is a list of sentences.\n",
        "raw_sentences = corpus_raw.split('.')\n",
        "sentences = []\n",
        "for sentence in raw_sentences:\n",
        "    sentences.append(sentence.split())"
      ],
      "metadata": {
        "id": "tz97kWTiV6C6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OnNrv1NV70E",
        "outputId": "dd6617f4-2326-4c45-f5c2-33dd82d7a872"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['he', 'is', 'the', 'king'], ['the', 'king', 'is', 'royal'], ['she', 'is', 'the', 'royal', 'queen'], []]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert this to an input output pair such that if we input a word, it should it predict that the neighbouring words : the `n` words before and after it, where `n` is the parameter window_size Here’s a handy example from this amazing post on word2vec by Chris McCormick.\n",
        "\n",
        "Now, we will generate our training data:"
      ],
      "metadata": {
        "id": "GB97P8tFWFls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "WINDOW_SIZE = 2\n",
        "for sentence in sentences:\n",
        "    for word_index, word in enumerate(sentence):\n",
        "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if nb_word != word:\n",
        "                train_data.append([word, nb_word])"
      ],
      "metadata": {
        "id": "zwiz8jmwWAkO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO2iKQcfWCV7",
        "outputId": "88b2b679-c4f7-4708-9fc1-161118dae72f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['he', 'is'], ['he', 'the'], ['is', 'he'], ['is', 'the'], ['is', 'king'], ['the', 'he'], ['the', 'is'], ['the', 'king'], ['king', 'is'], ['king', 'the'], ['the', 'king'], ['the', 'is'], ['king', 'the'], ['king', 'is'], ['king', 'royal'], ['is', 'the'], ['is', 'king'], ['is', 'royal'], ['royal', 'king'], ['royal', 'is'], ['she', 'is'], ['she', 'the'], ['is', 'she'], ['is', 'the'], ['is', 'royal'], ['the', 'she'], ['the', 'is'], ['the', 'royal'], ['the', 'queen'], ['royal', 'is'], ['royal', 'the'], ['royal', 'queen'], ['queen', 'the'], ['queen', 'royal']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert the word to one hot encoding."
      ],
      "metadata": {
        "id": "D0nUOn1JYfN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert numbers to one hot vectors\n",
        "def to_one_hot(data_point_index, vocab_size):\n",
        "    temp = np.zeros(vocab_size)\n",
        "    temp[data_point_index] = 1\n",
        "    return temp\n",
        "x_train = [] # input word\n",
        "y_train = [] # output word\n",
        "for w in train_data:\n",
        "    x_train.append(to_one_hot(word2int[ w[0] ], vocab_size))\n",
        "    y_train.append(to_one_hot(word2int[ w[1] ], vocab_size))\n",
        "# convert them to numpy arrays\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "metadata": {
        "id": "WePgEmA7WKyu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make the tensorflow model\n",
        "Since tf.placeholder is no loger avaialbe for tf version2, we have to make it compatible with version 1.\n"
      ],
      "metadata": {
        "id": "dB66ym0Dy5VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making placeholders for x_train and y_train\n",
        "# prepare the input layer\n",
        "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
        "# prepare the output layer\n",
        "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
      ],
      "metadata": {
        "id": "BPTSoeO1y46m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the training data and convert into the embedded representation.\n",
        "\n"
      ],
      "metadata": {
        "id": "WYvEO9Hy11bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare hidden layer\n",
        "EMBEDDING_DIM = 5 # you can choose your own number\n",
        "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
        "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM])) #bias\n",
        "hidden_representation = tf.add(tf.matmul(x,W1), b1)"
      ],
      "metadata": {
        "id": "d71UAwVd031K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take what we have in the embedded dimension and make a prediction about the neighbour. To make the prediction we use softmax."
      ],
      "metadata": {
        "id": "a8SSG4_D5QSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
        "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))"
      ],
      "metadata": {
        "id": "v4_wPzxN1LoN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "p_nawFbY5sAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) #make sure you do this!\n",
        "# define the loss function:\n",
        "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
        "# define the training step:\n",
        "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
        "n_iters = 100\n",
        "# train for n_iter iterations\n",
        "for _ in range(n_iters):\n",
        "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
        "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))"
      ],
      "metadata": {
        "id": "2i2vECNA1R8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All we are interested in is W1 and b1, i.e., the hidden representations."
      ],
      "metadata": {
        "id": "-N39yEZY9rLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sess.run(W1))\n",
        "print('----------')\n",
        "print(sess.run(b1))\n",
        "print('----------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHivmMmj89Ff",
        "outputId": "ad34a9f4-9be0-4578-d9dd-1ab6e32b5710"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.45049655  0.23794949  1.0837411   0.7330557  -1.1479896 ]\n",
            " [ 0.5940842  -0.37111065  0.00471259  0.10642298  1.1848685 ]\n",
            " [-0.63921785  0.7289111   0.28587317 -1.6626531   0.0632097 ]\n",
            " [-1.7174872   0.4385366  -0.07284818 -0.7544709   0.53131527]\n",
            " [ 0.7432065   0.26722872  0.8357407   0.96763146 -0.33866566]\n",
            " [-0.20846169  1.5346657   1.5455717   1.2498138  -0.195111  ]\n",
            " [-0.52655786  0.5873418   1.8670385   1.078154   -0.8207269 ]]\n",
            "----------\n",
            "[-0.3442267  -0.9412341  -1.7505565   0.38269332 -0.03693294]\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we multiply the one hot vectors with W1 , we basically get access to the row of the of W1 which is in fact the embedded representation of the word represented by the input one hot vector. So W1is essentially acting as a look up table.\n",
        "In our case we have also included a bias term b1 so you have to add it."
      ],
      "metadata": {
        "id": "-hMGcX7K9jRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = sess.run(W1 + b1)\n",
        "\n",
        "# if you work it out, you will see that it has the same effect as running the node hidden representation\n",
        "print(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StFc_HNc9Zqh",
        "outputId": "1f705fc6-c1d4-414f-f15d-060938db6b16"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.10626987 -0.7032846  -0.6668154   1.115749   -1.1849226 ]\n",
            " [ 0.24985752 -1.3123448  -1.7458439   0.4891163   1.1479355 ]\n",
            " [-0.9834446  -0.21232301 -1.4646833  -1.2799598   0.02627676]\n",
            " [-2.061714   -0.50269747 -1.8234047  -0.37177756  0.49438232]\n",
            " [ 0.3989798  -0.6740054  -0.9148158   1.3503247  -0.3755986 ]\n",
            " [-0.55268836  0.5934316  -0.20498478  1.6325071  -0.23204395]\n",
            " [-0.8707845  -0.35389233  0.11648202  1.4608473  -0.8576598 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_dist(vec1, vec2):\n",
        "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
        "def find_closest(word_index, vectors):\n",
        "    min_dist = 10000 # to act like positive infinity\n",
        "    min_index = -1\n",
        "    query_vector = vectors[word_index]\n",
        "    for index, vector in enumerate(vectors):\n",
        "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
        "            min_dist = euclidean_dist(vector, query_vector)\n",
        "            min_index = index\n",
        "    return min_index"
      ],
      "metadata": {
        "id": "KPI4YMk09Pw1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(int2word[find_closest(word2int['king'], vectors)])\n",
        "print(int2word[find_closest(word2int['queen'], vectors)])\n",
        "print(int2word[find_closest(word2int['royal'], vectors)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkyte-2r9SiV",
        "outputId": "6a9cd2b3-622f-425b-94fa-4934b0d8e6fd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "royal\n",
            "is\n",
            "king\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "model = TSNE(n_components=2, random_state=0)\n",
        "np.set_printoptions(suppress=True)\n",
        "vectors = model.fit_transform(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1P-dNaJ9eU_",
        "outputId": "f4c9c942-2d85-4231-df5b-d009f4857a73"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "normalizer = preprocessing.Normalizer()\n",
        "vectors =  normalizer.fit_transform(vectors, 'l2')"
      ],
      "metadata": {
        "id": "iF-00Ace982C"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "for word in words:\n",
        "    print(word, vectors[word2int[word]][1])\n",
        "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
        "    \n",
        "ax.set_xlim(min([vectors[word2int[w]][0] for w in words])-1, max([vectors[word2int[w]][0] for w in words])+1)\n",
        "ax.set_ylim(min([vectors[word2int[w]][1] for w in words])-1, max([vectors[word2int[w]][1] for w in words])+1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "em5sRiAc9-5D",
        "outputId": "d05b77cd-9ad1-4522-c45b-4035308c80db"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "royal 0.89717036\n",
            "he 0.25030422\n",
            "the 0.96019673\n",
            "she 0.5068005\n",
            "king -0.9047838\n",
            "is 0.9838481\n",
            "queen -0.4028841\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}